lwll:
  base_url: https://api-dev.lollllz.com/
  task_id: 06023f86-a66b-4b2c-8b8b-951f5edd0f22
  user_secret: <TODO: add >  # Coral
  session_name: TG's sample MT
  data_type: full   # sample
  data_path: /Users/tg/work/isi/lwll/datasets/development
model_args:
  src_vocab: 8000
  tgt_vocab: 8000
  enc_layers: 1
  dec_layers: 2
  hid_size: 128
  ff_size: 256
  n_heads: 2
  attn_bias: true
  attn_dropout: 0.1
  dropout: 0.2
  activation: relu
  tied_emb: one-way
model_type: tfmnmt
optim:
  name: ADAM
  args:
    betas:
    - 0.9
    - 0.98
    eps: 1.0e-09
    label_smoothing: 0.1
    lr: 0.1
    warmup_steps: 4000
    criterion: smooth_kld
    constant: 2
    amsgrad: false
    weight_decay: 0
    inv_sqrt: false
prep:
  max_src_types: 4000
  max_tgt_types: 4000
  char_coverage: 0.9998
  pieces: bpe
  shared_vocab: false
  src_len: 128
  tgt_len: 128
  truncate: false
  mono_src:
  - /Users/tg/work/isi/lwll/datasets/monolingual_corpora/wiki-ar.10k.tok
  mono_tgt:
  - /Users/tg/work/isi/lwll/datasets/monolingual_corpora/wiki-en.10k.tok
tester:
  decoder:
    beam_size: 2
    batch_size: 800 # 12000 # this is for 1 beam; effective_batch_size = batch_size / beam_size
    lp_alpha: 0.0     # length penalty
    #ensemble: 5  TODO: support ensemble
    max_len: 50
trainer:
  init_args:
    chunk_size: 10
  batch_size: 200
  check_point: 200
  keep_models: 10
  steps: 200
updated_at: '2020-07-03T22:11:14.352115'
seed: 12345
